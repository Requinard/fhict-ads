{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition with Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_In this notebook, we show how to perform face recognition using Support Vector Machines. We will use the Olivetti faces dataset, included in Scikit-learn. More info at: http://scikit-learn.org/stable/datasets/olivetti_faces.html_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing numpy, scikit-learn, and matplotlib, the Python libraries we will be using in this chapter. Show the versions we will be using (in case you have problems running the notebooks) and use the inline plotting mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Olivetti Face dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the olivetti faces dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Olivetti faces dataset.\n",
      "\n",
      "The original database was available from (now defunct)\n",
      "\n",
      "    http://www.uk.research.att.com/facedatabase.html\n",
      "\n",
      "The version retrieved here comes in MATLAB format from the personal\n",
      "web page of Sam Roweis:\n",
      "\n",
      "    http://www.cs.nyu.edu/~roweis/\n",
      "\n",
      "There are ten different images of each of 40 distinct subjects. For some\n",
      "subjects, the images were taken at different times, varying the lighting,\n",
      "facial expressions (open / closed eyes, smiling / not smiling) and facial\n",
      "details (glasses / no glasses). All the images were taken against a dark\n",
      "homogeneous background with the subjects in an upright, frontal position (with\n",
      "tolerance for some side movement).\n",
      "\n",
      "The original dataset consisted of 92 x 112, while the Roweis version\n",
      "consists of 64x64 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "# Fetch the faces data\n",
    "faces = fetch_olivetti_faces()\n",
    "\n",
    "print(faces.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Investigate the Olivetti Face DatasetÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data, faces.images has 400 images of faces, each one is composed by a matrix of 64x64 pixels.\n",
    "faces.data has the same data but in rows of 4096 attributes instead of matrices (4096 = 64x64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['images', 'target', 'DESCR', 'data'])\n",
      "(400, 64, 64)\n",
      "(400, 4096)\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "print(faces.keys())\n",
    "print(faces.images.shape)\n",
    "print(faces.data.shape)\n",
    "print(faces.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have to scale attributes, because data is already normalized. Prove this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all the faces in a matrix of 20x20, for each one, we'll put the target value in the top left corner and it's index in the bottom left corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Analysis with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to build a classifier whose model is a hyperplane that separates instances (points) of one class from the rest. Support Vector Machines (SVM) are supervised learning methods that try to obtain these hyperplanes in an optimal way, by selecting the ones that pass through the widest possible gaps between instances of different classes. New instances will be classified as belonging to a certain category based on which side of the surfaces they fall on. Let's import the SVC class from the sklearn.svm module. SVC stands for Support Vector Classifier: we will use SVM for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_1 = SVC(kernel='linear')\n",
    "print(svc_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Build training and testing sets and perform 5-fold cross-validation (use the ``sklearn.cross_validation`` package for this). Show what all the accuracy scores are and compute the average value. Consult the sklearn documentation and when needed ask your teacher for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Other Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the sklearn ``metrics`` package and determine also precision and recall for the test set, for _each class_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Accuracy on training set:\")\n",
    "    print(clf.score(X_train, y_train))\n",
    "    print(\"Accuracy on testing set:\")\n",
    "    print(clf.score(X_test, y_test))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure precision and recall on the evaluation set, for _each class_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "1.0\n",
      "Accuracy on testing set:\n",
      "0.99\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92         6\n",
      "          1       1.00      1.00      1.00         4\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       1.00      1.00      1.00         5\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      0.67      0.80         3\n",
      "          9       1.00      1.00      1.00         1\n",
      "         10       1.00      1.00      1.00         4\n",
      "         11       1.00      1.00      1.00         1\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         3\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         4\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       1.00      1.00      1.00         2\n",
      "         23       1.00      1.00      1.00         1\n",
      "         24       1.00      1.00      1.00         2\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         4\n",
      "         27       1.00      1.00      1.00         1\n",
      "         28       1.00      1.00      1.00         2\n",
      "         29       1.00      1.00      1.00         3\n",
      "         30       1.00      1.00      1.00         4\n",
      "         31       1.00      1.00      1.00         3\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         3\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         3\n",
      "         37       1.00      1.00      1.00         3\n",
      "         38       1.00      1.00      1.00         1\n",
      "         39       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       0.99      0.99      0.99       100\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6 0 0 ..., 0 0 0]\n",
      " [0 4 0 ..., 0 0 0]\n",
      " [0 0 2 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 3 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(svc_1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion performance of SVM for face recognition is incredibly high!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Discriminate People with or without Glasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, another problem: Let's try to classify images of people with and without glasses. Mark people with glasses as 1 and people without glasses as 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and test set for the new problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try again with a linear SVM kernel and show a classification report as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
