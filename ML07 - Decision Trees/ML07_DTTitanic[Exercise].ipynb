{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who Survived the Titanic Disaster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this titanic example we will use decision trees. The main advantage of this model is that a human being can easily \n",
    "understand and reproduce the sequence of decisions (especially if the number of attributes is small) taken to predict the target class of a new instance.\n",
    "\n",
    "This is very important for tasks such as medical diagnosis or credit approval, where we want to show a reason for the \n",
    "decision, rather than just saying this is what the training data suggests (which is, by definition, what every supervised \n",
    "learning method does).\n",
    "\n",
    "The problem we would like to solve is to determine if a Titanic's passenger would have survived, given age, passenger class, \n",
    "and sex. Why these features? \n",
    "\n",
    "Very specific features or attributes (such as name in our case) could result in overfitting (consider a tree that just asks \n",
    "if the name is X, she survived); attributes where there is a small number of instances with each value present a similar \n",
    "problem. They might not be useful for generalization. We will use class, age, and sex because a priori, we expect them to \n",
    "have possibly influenced the passenger's survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each instance in the dataset has the following form:\n",
    "\n",
    "     \"1\",\"1st\",1,\"Allen, Miss Elisabeth Walton\",29.0000,\"Southampton\",\"St Louis, MO\",\"B-5\",\"24160 L221\",\"2\",\"female\"\n",
    "     \n",
    "Note that the raw data consists largely of strings. To apply machine learning algo's it has to be converted to numerical data first (at least the columns that are of interest)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Dataset with Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a Python module to works with the so-called dataframe concept (a bit like in R - rows are observations, columns refer to the features).\n",
    "\n",
    "A dataframe is essentially a two-dimensional labeled data structure where\n",
    "columns can potentially include different data types and each row represents an\n",
    "obervation).\n",
    "\n",
    "More details, see: https://www.kaggle.com/c/titanic/details/getting-started-with-python-ii "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names pclass  survived                                 name  age  \\\n",
       "0          1    1st         1         Allen, Miss Elisabeth Walton   29   \n",
       "1          2    1st         0          Allison, Miss Helen Loraine    2   \n",
       "2          3    1st         0  Allison, Mr Hudson Joshua Creighton   30   \n",
       "\n",
       "      embarked                        home.dest room      ticket   boat  \\\n",
       "0  Southampton                     St Louis, MO  B-5  24160 L221      2   \n",
       "1  Southampton  Montreal, PQ / Chesterville, ON  C26         NaN    NaN   \n",
       "2  Southampton  Montreal, PQ / Chesterville, ON  C26         NaN  (135)   \n",
       "\n",
       "      sex  \n",
       "0  female  \n",
       "1  female  \n",
       "2    male  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For .read_csv, always use header=0 when you know row 0 is the header row\n",
    "df_titanic = pd.read_csv('C:/Users/885299/scikit_learn_data/Titanic.csv', header = 0)\n",
    "\n",
    "# Show the first 3 observations (with column names) ...\n",
    "df_titanic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1310</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Maprieder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1311</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zenn, Mr Philip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1312</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zievens, Rene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1313</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      row.names pclass  survived                    name  age embarked  \\\n",
       "1309       1310    3rd         0  Zakarian, Mr Maprieder  NaN      NaN   \n",
       "1310       1311    3rd         0         Zenn, Mr Philip  NaN      NaN   \n",
       "1311       1312    3rd         0           Zievens, Rene  NaN      NaN   \n",
       "1312       1313    3rd         0          Zimmerman, Leo  NaN      NaN   \n",
       "\n",
       "     home.dest room ticket boat     sex  \n",
       "1309       NaN  NaN    NaN  NaN    male  \n",
       "1310       NaN  NaN    NaN  NaN    male  \n",
       "1311       NaN  NaN    NaN  NaN  female  \n",
       "1312       NaN  NaN    NaN  NaN    male  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and the last 4 observations \n",
    "df_titanic.tail(4)\n",
    "\n",
    "# Note: We have missing values (some features are not available), a usual problem with datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Investigate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row.names      int64\n",
       "pclass        object\n",
       "survived       int64\n",
       "name          object\n",
       "age          float64\n",
       "embarked      object\n",
       "home.dest     object\n",
       "room          object\n",
       "ticket        object\n",
       "boat          object\n",
       "sex           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does Pandas interpret the data (using the csv reader)?\n",
    "df_titanic.dtypes\n",
    "\n",
    "# Note: Pandas is able to infer numerical types whenever it can detect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1313 entries, 0 to 1312\n",
      "Data columns (total 11 columns):\n",
      "row.names    1313 non-null int64\n",
      "pclass       1313 non-null object\n",
      "survived     1313 non-null int64\n",
      "name         1313 non-null object\n",
      "age          633 non-null float64\n",
      "embarked     821 non-null object\n",
      "home.dest    754 non-null object\n",
      "room         77 non-null object\n",
      "ticket       69 non-null object\n",
      "boat         347 non-null object\n",
      "sex          1313 non-null object\n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 123.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# There are two more very valuable commands to learn on a dataframe, the first is:\n",
    "df_titanic.info()\n",
    "\n",
    "# Note: This gives a lot of useful info! \n",
    "# You can see immediately we have 1313 entries (rows), and for some (name, sex, pclass, survived) of the variables we \n",
    "# have complete values. Room (or cabin) is only known in 77 cases. Missing values is a very common problem with \n",
    "# datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>633.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>657.000000</td>\n",
       "      <td>0.341965</td>\n",
       "      <td>31.194181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>379.174762</td>\n",
       "      <td>0.474549</td>\n",
       "      <td>14.747525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>329.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>657.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>985.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         row.names     survived         age\n",
       "count  1313.000000  1313.000000  633.000000\n",
       "mean    657.000000     0.341965   31.194181\n",
       "std     379.174762     0.474549   14.747525\n",
       "min       1.000000     0.000000    0.166700\n",
       "25%     329.000000     0.000000   21.000000\n",
       "50%     657.000000     0.000000   30.000000\n",
       "75%     985.000000     1.000000   41.000000\n",
       "max    1313.000000     1.000000   71.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and the second is:\n",
    "df_titanic.describe()\n",
    "\n",
    "# Also very useful: Pandas has taken all of the numerical columns and quickly calculated the mean, std, minimum \n",
    "# and maximum value. Convenient! But also a word of caution: we know there are a lot of missing values in Age, for example. \n",
    "# How did pandas deal with that? It must have left out any nulls from the calculation. \n",
    "# So if we start quoting the \"average age on the Titanic\" we need to caveat how we derived that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29.0000\n",
       "1     2.0000\n",
       "2    30.0000\n",
       "3    25.0000\n",
       "4     0.9167\n",
       "5    47.0000\n",
       "6    63.0000\n",
       "7    39.0000\n",
       "8    58.0000\n",
       "9    71.0000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntax in Pandas that allows for referring to specific columns is easy to remember. Slice the first 10 rows of the \n",
    "# 'age' column. In pandas this is:\n",
    "df_titanic['age'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What kind of object is this:     \n",
    "type(df_titanic['age'])\n",
    "\n",
    "# Note: Single column is neither an numpy array, nor a pandas dataframe but rather a pandas-specific object called \n",
    "# data Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.19418104265403"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mean value of the age column:\n",
    "df_titanic['age'].mean()\n",
    "\n",
    "# Note: That matches what was reported in df_titanic.describe()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>47.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>63.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>39.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>58.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>71.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>47.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>19.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>24.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>36.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>37.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>47.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>26.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>19.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>28.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>45.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>39.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>58.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>female</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>male</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex pclass      age\n",
       "0     female    1st  29.0000\n",
       "1     female    1st   2.0000\n",
       "2       male    1st  30.0000\n",
       "3     female    1st  25.0000\n",
       "4       male    1st   0.9167\n",
       "5       male    1st  47.0000\n",
       "6     female    1st  63.0000\n",
       "7       male    1st  39.0000\n",
       "8     female    1st  58.0000\n",
       "9       male    1st  71.0000\n",
       "10      male    1st  47.0000\n",
       "11    female    1st  19.0000\n",
       "12    female    1st      NaN\n",
       "13      male    1st      NaN\n",
       "14      male    1st      NaN\n",
       "15    female    1st  50.0000\n",
       "16      male    1st  24.0000\n",
       "17      male    1st  36.0000\n",
       "18      male    1st  37.0000\n",
       "19    female    1st  47.0000\n",
       "20      male    1st  26.0000\n",
       "21      male    1st  25.0000\n",
       "22      male    1st  25.0000\n",
       "23    female    1st  19.0000\n",
       "24      male    1st  28.0000\n",
       "25      male    1st  45.0000\n",
       "26      male    1st  39.0000\n",
       "27    female    1st  30.0000\n",
       "28    female    1st  58.0000\n",
       "29      male    1st      NaN\n",
       "...      ...    ...      ...\n",
       "1283  female    3rd      NaN\n",
       "1284    male    3rd      NaN\n",
       "1285    male    3rd      NaN\n",
       "1286    male    3rd      NaN\n",
       "1287    male    3rd      NaN\n",
       "1288    male    3rd      NaN\n",
       "1289    male    3rd      NaN\n",
       "1290    male    3rd      NaN\n",
       "1291    male    3rd      NaN\n",
       "1292    male    3rd      NaN\n",
       "1293  female    3rd      NaN\n",
       "1294    male    3rd      NaN\n",
       "1295    male    3rd      NaN\n",
       "1296    male    3rd      NaN\n",
       "1297    male    3rd      NaN\n",
       "1298    male    3rd      NaN\n",
       "1299    male    3rd      NaN\n",
       "1300    male    3rd      NaN\n",
       "1301    male    3rd      NaN\n",
       "1302    male    3rd      NaN\n",
       "1303    male    3rd      NaN\n",
       "1304  female    3rd      NaN\n",
       "1305    male    3rd      NaN\n",
       "1306  female    3rd      NaN\n",
       "1307  female    3rd      NaN\n",
       "1308    male    3rd      NaN\n",
       "1309    male    3rd      NaN\n",
       "1310    male    3rd      NaN\n",
       "1311  female    3rd      NaN\n",
       "1312    male    3rd      NaN\n",
       "\n",
       "[1313 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next thing we'd like to do is look at more specific subsets of the dataframe. Again pandas makes this very \n",
    "# convenient to write. Pass it a [ list ] of the columns desired:\n",
    "df_titanic[ ['sex', 'pclass', 'age'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>female</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>male</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex pclass  age\n",
       "12  female    1st  NaN\n",
       "13    male    1st  NaN\n",
       "14    male    1st  NaN\n",
       "29    male    1st  NaN\n",
       "32    male    1st  NaN\n",
       "35    male    1st  NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First look at all of the missing 'age' values, because we will need to address them in our model if we hope to use \n",
    "# all the data for more advanced algorithms. To filter for missing values, use:\n",
    "df_titanic[df_titanic['age'].isnull()][['sex', 'pclass', 'age']].head(6)\n",
    "\n",
    "# Note: Here the only thing we did was print all 680 cases, but the same syntax can be used later if we take action on \n",
    "# them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Before we finish the initial investigation by hand, let's use one other convenience function of pandas to derive a \n",
    "# histogram of any numerical column. The histogram function is really a shortcut to the more powerful features of the \n",
    "# matplotlib/pylab packages, so let's be sure that's imported. Type the following:\n",
    "import pylab as pyl\n",
    "df_titanic['age'].hist()\n",
    "pyl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inside the parentheses of .hist(), you can also be more explicit about options of this function. Before you invoke \n",
    "# it, you can also be explicit that you are dropping the missing values of age:\n",
    "df_titanic['age'].dropna().hist(bins=16, range=(0,80), alpha = .5)\n",
    "pyl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Transform the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names pclass  survived                                 name  age  \\\n",
       "0          1    1st         1         Allen, Miss Elisabeth Walton   29   \n",
       "1          2    1st         0          Allison, Miss Helen Loraine    2   \n",
       "2          3    1st         0  Allison, Mr Hudson Joshua Creighton   30   \n",
       "\n",
       "      embarked                        home.dest room      ticket   boat  \\\n",
       "0  Southampton                     St Louis, MO  B-5  24160 L221      2   \n",
       "1  Southampton  Montreal, PQ / Chesterville, ON  C26         NaN    NaN   \n",
       "2  Southampton  Montreal, PQ / Chesterville, ON  C26         NaN  (135)   \n",
       "\n",
       "      sex  Gender  \n",
       "0  female       4  \n",
       "1  female       4  \n",
       "2    male       4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the values in the dataframe into the shape we need for machine learning. First of all, it's hard to run \n",
    "# analysis on the string values of \"male\" and \"female\". \n",
    "# Let's store our transformation in a new column, so the original sex isn't changed.\n",
    "# In Pandas, adding a column is as easy as naming it and passing it new values (in this arbitrarily a 4).\n",
    "df_titanic['Gender'] = 4\n",
    "df_titanic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names pclass  survived                                 name  age  \\\n",
       "0          1    1st         1         Allen, Miss Elisabeth Walton   29   \n",
       "1          2    1st         0          Allison, Miss Helen Loraine    2   \n",
       "2          3    1st         0  Allison, Mr Hudson Joshua Creighton   30   \n",
       "\n",
       "      embarked                        home.dest room      ticket   boat  \\\n",
       "0  Southampton                     St Louis, MO  B-5  24160 L221      2   \n",
       "1  Southampton  Montreal, PQ / Chesterville, ON  C26         NaN    NaN   \n",
       "2  Southampton  Montreal, PQ / Chesterville, ON  C26         NaN  (135)   \n",
       "\n",
       "      sex  Gender  \n",
       "0  female       0  \n",
       "1  female       0  \n",
       "2    male       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's transform Gender into values of 0 and 1's. We have a precedent of analyzing the women first, so let's decide \n",
    "# female = 0 and male = 1. \n",
    "df_titanic['Gender'] = df_titanic['sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "df_titanic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names pclass  survived                                 name  age  \\\n",
       "0          1    1st         1         Allen, Miss Elisabeth Walton   29   \n",
       "1          2    1st         0          Allison, Miss Helen Loraine    2   \n",
       "2          3    1st         0  Allison, Mr Hudson Joshua Creighton   30   \n",
       "\n",
       "      embarked                        home.dest room      ticket   boat  \\\n",
       "0  Southampton                     St Louis, MO  B-5  24160 L221      2   \n",
       "1  Southampton  Montreal, PQ / Chesterville, ON  C26         NaN    NaN   \n",
       "2  Southampton  Montreal, PQ / Chesterville, ON  C26         NaN  (135)   \n",
       "\n",
       "      sex  Gender  PClass  \n",
       "0  female       0       1  \n",
       "1  female       0       1  \n",
       "2    male       1       1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same for passenger class, make it numeric, in a new column PClass. \n",
    "df_titanic['PClass'] = df_titanic['pclass'].map( {'1st': 1, '2nd': 2, '3rd' : 3} ).astype(int)\n",
    "df_titanic.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Deal with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to deal with the missing values of age! Why? Simply because most machine learning will need a complete set of \n",
    "values in that column to use it. By filling it in with guesses, we'll be introducing some noise into a model, but if we can \n",
    "keep our guesses reasonable, some of them should be close to the historical truth (whatever it was...), and the overall \n",
    "predictive power of age might still make a better model than before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>323</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Abelson, Mr Samuel</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>Russia New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>325</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Andrew, Mr Edgar Samuel</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Buenos Aires, Argentina / New Jersey, NJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>326</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Andrew, Mr Frank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Cornwall, England Houghton, MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>327</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Angle, Mr William A.</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Warwick, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>329</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Ashby, Mr John</td>\n",
       "      <td>57.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>West Hoboken, NJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>330</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Bailey, Mr Percy Andrew</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Penzance, Cornwall / Akron, OH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>331</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Baimbrigge, Mr Charles R.</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Guernsey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>333</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Banfield, Mr Frederick J.</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Plymouth, Dorset / Houghton, MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>334</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Bateman, Rev Robert James</td>\n",
       "      <td>51.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Jacksonville, FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(174)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>335</td>\n",
       "      <td>2nd</td>\n",
       "      <td>1</td>\n",
       "      <td>Beane, Mr Edward</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Norwich / New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>337</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Beauchamp, Mr Henry James</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>340</td>\n",
       "      <td>2nd</td>\n",
       "      <td>1</td>\n",
       "      <td>Becker, Master Richard F.</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Guntur, India / Benton Harbour, MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230136 L39</td>\n",
       "      <td>11</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>342</td>\n",
       "      <td>2nd</td>\n",
       "      <td>1</td>\n",
       "      <td>Beesley, Mr Lawrence</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>London</td>\n",
       "      <td>D-56</td>\n",
       "      <td>248698 L13</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>344</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Berriman, Mr William S.</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Ives, Cornwall / Calumet, MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>345</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Botsford, Mr William Hull</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Elmira, NY / Orange, NJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>346</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Bowenur, Mr Solomon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>347</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Bracken, Mr James H.</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Lake Arthur, Chavez County, NM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>349</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Brown, Mr Thomas William Solomon</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Cape Town, South Africa / Seattle, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>352</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Bryhl, Mr Kurt Arnold Gottfrid</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Skara, Sweden / Rockford, IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>354</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Butler, Mr Reginald Fenton</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Southsea, Hants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(97)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>355</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Byles, Rev. Thomas Roussel D.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>357</td>\n",
       "      <td>2nd</td>\n",
       "      <td>1</td>\n",
       "      <td>Caldwell, Mr Albert Francis</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Bangkok, Thailand / Roseville, IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>359</td>\n",
       "      <td>2nd</td>\n",
       "      <td>1</td>\n",
       "      <td>Caldwell, Master Alden Gates</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Bangkok, Thailand / Roseville, IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>361</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Campbell, Mr William</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>362</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Carbines, Mr William</td>\n",
       "      <td>19.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Ives, Cornwall / Calumet, MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(18)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>363</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Carter, Rev Ernest Courtenay</td>\n",
       "      <td>54.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>365</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapman, Mr Charles Henry</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Bronx, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(130)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>366</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapman, Mr John Henry</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Cornwall / Spokane, WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(17)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>370</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Clarke, Mr Charles V.</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>England / San Francisco, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>372</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Coleridge, Mr Reginald Charles</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Hartford, Huntingdonshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>545</td>\n",
       "      <td>2nd</td>\n",
       "      <td>1</td>\n",
       "      <td>Richards, Master George Sidney</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>547</td>\n",
       "      <td>2nd</td>\n",
       "      <td>1</td>\n",
       "      <td>Richards, Master William Rowe</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>549</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Rogers, Mr Harry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>551</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Sedgwick, Mr Charles Frederick Waddington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>552</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Sharp, Mr Percival</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Hornsey, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>557</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Sjostedt, Mr Ernst Adolf</td>\n",
       "      <td>59.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Sault St Marie, ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>559</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Slemen, Mr Richard James</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Cornwall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>560</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Smith (Schmidt), Mr Augustus</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>562</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Sobey, Mr Hayden</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Cornwall / Houghton, MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>563</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Stanton, Mr Samuel Ward</td>\n",
       "      <td>41.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>564</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Stokes, Mr Philip Joseph</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Catford, Kent / Detroit, MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(81)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>565</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Sweet, Mr George</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Somerset / Bernardsville, NJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>567</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Troupiansky, Mr Moses Aaron</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>570</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Turpin, Mr William John</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Plymouth, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>572</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Veale, Mr James</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Barre, Co Washington, VT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>573</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Waelens, Mr Achille</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Antwerp, Belgium / Stanton, OH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(140)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>575</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Ware, Mr John James</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Bristol, England / New Britain, CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>577</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Ware, Mr William J.</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>578</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Watson, Mr Ennis Hastings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>582</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Weisz, Mr Leopold</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Bromsgrove, England / Montreal, PQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(293)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>586</td>\n",
       "      <td>2nd</td>\n",
       "      <td>1</td>\n",
       "      <td>Wells, Master Ralph Lester</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>589</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>West, Mr Edwy Arthur</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Bournmouth, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>591</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Wheadon, Mr Edward</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Guernsey, England / Edgewood, RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>592</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Wheeler, Mr Edwin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>593</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Wheeler, Mr Frederick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>594</td>\n",
       "      <td>2nd</td>\n",
       "      <td>1</td>\n",
       "      <td>Wilhelms, Mr Charles</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>London, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>596</td>\n",
       "      <td>2nd</td>\n",
       "      <td>1</td>\n",
       "      <td>Williams, Mr Charles Eugene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Harrow, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>599</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Aldworth, Mr Charles Augustus</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Bryn Mawr, PA, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248744 L13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>601</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Pernot, Mr Rene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2131</td>\n",
       "      <td>L15 1s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>602</td>\n",
       "      <td>2nd</td>\n",
       "      <td>0</td>\n",
       "      <td>Swane, Mr George</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(294)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row.names pclass  survived                                       name  \\\n",
       "322        323    2nd         0                         Abelson, Mr Samuel   \n",
       "324        325    2nd         0                    Andrew, Mr Edgar Samuel   \n",
       "325        326    2nd         0                           Andrew, Mr Frank   \n",
       "326        327    2nd         0                       Angle, Mr William A.   \n",
       "328        329    2nd         0                             Ashby, Mr John   \n",
       "329        330    2nd         0                    Bailey, Mr Percy Andrew   \n",
       "330        331    2nd         0                  Baimbrigge, Mr Charles R.   \n",
       "332        333    2nd         0                  Banfield, Mr Frederick J.   \n",
       "333        334    2nd         0                  Bateman, Rev Robert James   \n",
       "334        335    2nd         1                           Beane, Mr Edward   \n",
       "336        337    2nd         0                  Beauchamp, Mr Henry James   \n",
       "339        340    2nd         1                  Becker, Master Richard F.   \n",
       "341        342    2nd         1                       Beesley, Mr Lawrence   \n",
       "343        344    2nd         0                    Berriman, Mr William S.   \n",
       "344        345    2nd         0                  Botsford, Mr William Hull   \n",
       "345        346    2nd         0                        Bowenur, Mr Solomon   \n",
       "346        347    2nd         0                       Bracken, Mr James H.   \n",
       "348        349    2nd         0           Brown, Mr Thomas William Solomon   \n",
       "351        352    2nd         0             Bryhl, Mr Kurt Arnold Gottfrid   \n",
       "353        354    2nd         0                 Butler, Mr Reginald Fenton   \n",
       "354        355    2nd         0              Byles, Rev. Thomas Roussel D.   \n",
       "356        357    2nd         1                Caldwell, Mr Albert Francis   \n",
       "358        359    2nd         1               Caldwell, Master Alden Gates   \n",
       "360        361    2nd         0                       Campbell, Mr William   \n",
       "361        362    2nd         0                       Carbines, Mr William   \n",
       "362        363    2nd         0               Carter, Rev Ernest Courtenay   \n",
       "364        365    2nd         0                  Chapman, Mr Charles Henry   \n",
       "365        366    2nd         0                     Chapman, Mr John Henry   \n",
       "369        370    2nd         0                      Clarke, Mr Charles V.   \n",
       "371        372    2nd         0             Coleridge, Mr Reginald Charles   \n",
       "..         ...    ...       ...                                        ...   \n",
       "544        545    2nd         1             Richards, Master George Sidney   \n",
       "546        547    2nd         1              Richards, Master William Rowe   \n",
       "548        549    2nd         0                           Rogers, Mr Harry   \n",
       "550        551    2nd         0  Sedgwick, Mr Charles Frederick Waddington   \n",
       "551        552    2nd         0                         Sharp, Mr Percival   \n",
       "556        557    2nd         0                   Sjostedt, Mr Ernst Adolf   \n",
       "558        559    2nd         0                   Slemen, Mr Richard James   \n",
       "559        560    2nd         0               Smith (Schmidt), Mr Augustus   \n",
       "561        562    2nd         0                           Sobey, Mr Hayden   \n",
       "562        563    2nd         0                    Stanton, Mr Samuel Ward   \n",
       "563        564    2nd         0                   Stokes, Mr Philip Joseph   \n",
       "564        565    2nd         0                           Sweet, Mr George   \n",
       "566        567    2nd         0                Troupiansky, Mr Moses Aaron   \n",
       "569        570    2nd         0                    Turpin, Mr William John   \n",
       "571        572    2nd         0                            Veale, Mr James   \n",
       "572        573    2nd         0                        Waelens, Mr Achille   \n",
       "574        575    2nd         0                        Ware, Mr John James   \n",
       "576        577    2nd         0                        Ware, Mr William J.   \n",
       "577        578    2nd         0                  Watson, Mr Ennis Hastings   \n",
       "581        582    2nd         0                          Weisz, Mr Leopold   \n",
       "585        586    2nd         1                 Wells, Master Ralph Lester   \n",
       "588        589    2nd         0                       West, Mr Edwy Arthur   \n",
       "590        591    2nd         0                         Wheadon, Mr Edward   \n",
       "591        592    2nd         0                          Wheeler, Mr Edwin   \n",
       "592        593    2nd         0                      Wheeler, Mr Frederick   \n",
       "593        594    2nd         1                       Wilhelms, Mr Charles   \n",
       "595        596    2nd         1                Williams, Mr Charles Eugene   \n",
       "598        599    2nd         0              Aldworth, Mr Charles Augustus   \n",
       "600        601    2nd         0                            Pernot, Mr Rene   \n",
       "601        602    2nd         0                           Swane, Mr George   \n",
       "\n",
       "         age     embarked                                 home.dest  room  \\\n",
       "322  30.0000    Cherbourg                       Russia New York, NY   NaN   \n",
       "324  18.0000  Southampton  Buenos Aires, Argentina / New Jersey, NJ   NaN   \n",
       "325      NaN  Southampton            Cornwall, England Houghton, MI   NaN   \n",
       "326  34.0000  Southampton                          Warwick, England   NaN   \n",
       "328  57.0000  Southampton                          West Hoboken, NJ   NaN   \n",
       "329  18.0000  Southampton            Penzance, Cornwall / Akron, OH   NaN   \n",
       "330  23.0000  Southampton                                  Guernsey   NaN   \n",
       "332  28.0000  Southampton           Plymouth, Dorset / Houghton, MI   NaN   \n",
       "333  51.0000  Southampton                          Jacksonville, FL   NaN   \n",
       "334  32.0000  Southampton                    Norwich / New York, NY   NaN   \n",
       "336  28.0000  Southampton                                   England   NaN   \n",
       "339   1.0000  Southampton        Guntur, India / Benton Harbour, MI   NaN   \n",
       "341  34.0000  Southampton                                    London  D-56   \n",
       "343  23.0000  Southampton           St Ives, Cornwall / Calumet, MI   NaN   \n",
       "344  26.0000  Southampton                   Elmira, NY / Orange, NJ   NaN   \n",
       "345      NaN  Southampton                                    London   NaN   \n",
       "346  27.0000  Southampton            Lake Arthur, Chavez County, NM   NaN   \n",
       "348  45.0000  Southampton     Cape Town, South Africa / Seattle, WA   NaN   \n",
       "351  25.0000  Southampton              Skara, Sweden / Rockford, IL   NaN   \n",
       "353  25.0000  Southampton                           Southsea, Hants   NaN   \n",
       "354      NaN  Southampton                                    London   NaN   \n",
       "356  26.0000  Southampton         Bangkok, Thailand / Roseville, IL   NaN   \n",
       "358   0.8333  Southampton         Bangkok, Thailand / Roseville, IL   NaN   \n",
       "360      NaN          NaN                                   Belfast   NaN   \n",
       "361  19.0000  Southampton           St Ives, Cornwall / Calumet, MI   NaN   \n",
       "362  54.0000  Southampton                                    London   NaN   \n",
       "364  52.0000  Southampton                                 Bronx, NY   NaN   \n",
       "365  30.0000  Southampton                    Cornwall / Spokane, WA   NaN   \n",
       "369  29.0000  Southampton               England / San Francisco, CA   NaN   \n",
       "371  29.0000  Southampton                 Hartford, Huntingdonshire   NaN   \n",
       "..       ...          ...                                       ...   ...   \n",
       "544   0.8333  Southampton                      Cornwall / Akron, OH   NaN   \n",
       "546   3.0000  Southampton                      Cornwall / Akron, OH   NaN   \n",
       "548      NaN  Southampton                                       NaN   NaN   \n",
       "550      NaN  Southampton                                 Liverpool   NaN   \n",
       "551      NaN  Southampton                          Hornsey, England   NaN   \n",
       "556  59.0000  Southampton                        Sault St Marie, ON   NaN   \n",
       "558  35.0000  Southampton                                  Cornwall   NaN   \n",
       "559  22.0000  Southampton                                Newark, NJ   NaN   \n",
       "561  25.0000  Southampton                   Cornwall / Houghton, MI   NaN   \n",
       "562  41.0000    Cherbourg                              New York, NY   NaN   \n",
       "563  25.0000  Southampton               Catford, Kent / Detroit, MI   NaN   \n",
       "564  14.0000  Southampton              Somerset / Bernardsville, NJ   NaN   \n",
       "566  22.0000  Southampton                                       NaN   NaN   \n",
       "569  29.0000  Southampton                         Plymouth, England   NaN   \n",
       "571  30.0000  Southampton                  Barre, Co Washington, VT   NaN   \n",
       "572  22.0000  Southampton            Antwerp, Belgium / Stanton, OH   NaN   \n",
       "574  30.0000  Southampton        Bristol, England / New Britain, CT   NaN   \n",
       "576  23.0000  Southampton                                       NaN   NaN   \n",
       "577      NaN  Southampton                                   Belfast   NaN   \n",
       "581  28.0000  Southampton        Bromsgrove, England / Montreal, PQ   NaN   \n",
       "585   2.0000  Southampton                      Cornwall / Akron, OH   NaN   \n",
       "588  36.0000  Southampton                       Bournmouth, England   NaN   \n",
       "590      NaN  Southampton          Guernsey, England / Edgewood, RI   NaN   \n",
       "591      NaN  Southampton                                       NaN   NaN   \n",
       "592      NaN          NaN                                       NaN   NaN   \n",
       "593  32.0000  Southampton                           London, England   NaN   \n",
       "595      NaN  Southampton                           Harrow, England   NaN   \n",
       "598  30.0000  Southampton                        Bryn Mawr, PA, USA   NaN   \n",
       "600      NaN    Cherbourg                                       NaN  2131   \n",
       "601  18.0000  Southampton                                       NaN   F-?   \n",
       "\n",
       "         ticket   boat   sex  Gender  PClass  \n",
       "322         NaN    NaN  male       1       2  \n",
       "324         NaN    NaN  male       1       2  \n",
       "325         NaN    NaN  male       1       2  \n",
       "326         NaN    NaN  male       1       2  \n",
       "328         NaN    NaN  male       1       2  \n",
       "329         NaN    NaN  male       1       2  \n",
       "330         NaN    NaN  male       1       2  \n",
       "332         NaN    NaN  male       1       2  \n",
       "333         NaN  (174)  male       1       2  \n",
       "334         NaN    NaN  male       1       2  \n",
       "336         NaN    NaN  male       1       2  \n",
       "339  230136 L39     11  male       1       2  \n",
       "341  248698 L13     13  male       1       2  \n",
       "343         NaN    NaN  male       1       2  \n",
       "344         NaN    NaN  male       1       2  \n",
       "345         NaN    NaN  male       1       2  \n",
       "346         NaN    NaN  male       1       2  \n",
       "348         NaN    NaN  male       1       2  \n",
       "351         NaN    NaN  male       1       2  \n",
       "353         NaN   (97)  male       1       2  \n",
       "354         NaN    NaN  male       1       2  \n",
       "356         NaN     13  male       1       2  \n",
       "358         NaN     13  male       1       2  \n",
       "360         NaN    NaN  male       1       2  \n",
       "361         NaN   (18)  male       1       2  \n",
       "362         NaN    NaN  male       1       2  \n",
       "364         NaN  (130)  male       1       2  \n",
       "365         NaN   (17)  male       1       2  \n",
       "369         NaN    NaN  male       1       2  \n",
       "371         NaN    NaN  male       1       2  \n",
       "..          ...    ...   ...     ...     ...  \n",
       "544         NaN      4  male       1       2  \n",
       "546         NaN      4  male       1       2  \n",
       "548         NaN    NaN  male       1       2  \n",
       "550         NaN    NaN  male       1       2  \n",
       "551         NaN    NaN  male       1       2  \n",
       "556         NaN    NaN  male       1       2  \n",
       "558         NaN    NaN  male       1       2  \n",
       "559         NaN    NaN  male       1       2  \n",
       "561         NaN    NaN  male       1       2  \n",
       "562         NaN    NaN  male       1       2  \n",
       "563         NaN   (81)  male       1       2  \n",
       "564         NaN    NaN  male       1       2  \n",
       "566         NaN    NaN  male       1       2  \n",
       "569         NaN    NaN  male       1       2  \n",
       "571         NaN    NaN  male       1       2  \n",
       "572         NaN  (140)  male       1       2  \n",
       "574         NaN    NaN  male       1       2  \n",
       "576         NaN    NaN  male       1       2  \n",
       "577         NaN    NaN  male       1       2  \n",
       "581         NaN  (293)  male       1       2  \n",
       "585         NaN    NaN  male       1       2  \n",
       "588         NaN    NaN  male       1       2  \n",
       "590         NaN    NaN  male       1       2  \n",
       "591         NaN    NaN  male       1       2  \n",
       "592         NaN    NaN  male       1       2  \n",
       "593         NaN      9  male       1       2  \n",
       "595         NaN     14  male       1       2  \n",
       "598  248744 L13    NaN  male       1       2  \n",
       "600      L15 1s    NaN  male       1       2  \n",
       "601         NaN  (294)  male       1       2  \n",
       "\n",
       "[173 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We know the average [known] age of all passengers is 31.2 - we could fill in the null values with that. But may be \n",
    "# the median would be better? (to reduce the influence of a few rare 70- and 80-year olds?) The age histogram did seem \n",
    "# positively skewed. These are the kind of decisions you make as you create your models (e.g. in a Kaggle competition).\n",
    "\n",
    "# For now let's decide to be more sophisticated, that we want to use the age that was typical in each passenger class \n",
    "# (and the data on passenger class is complete). \n",
    "\n",
    "# First show all males in the second class\n",
    "df_titanic[(df_titanic['Gender'] == 1) & (df_titanic['PClass'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 38.  28.  20.]\n",
      " [ 42.  28.  24.]]\n"
     ]
    }
   ],
   "source": [
    "# Let's build a reference table to calculate what each of these medians are:\n",
    "median_ages = np.zeros((2,3))\n",
    "\n",
    "# And then populating this array:\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        median_ages[i,j] = df_titanic[(df_titanic['Gender'] == i) & (df_titanic['PClass'] == j+1)]['age'].dropna().median()\n",
    " \n",
    "print(median_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PClass</th>\n",
       "      <th>AgeFill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names pclass  survived  \\\n",
       "0          1    1st         1   \n",
       "1          2    1st         0   \n",
       "2          3    1st         0   \n",
       "3          4    1st         0   \n",
       "4          5    1st         1   \n",
       "\n",
       "                                              name      age     embarked  \\\n",
       "0                     Allen, Miss Elisabeth Walton  29.0000  Southampton   \n",
       "1                      Allison, Miss Helen Loraine   2.0000  Southampton   \n",
       "2              Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   \n",
       "3  Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   \n",
       "4                    Allison, Master Hudson Trevor   0.9167  Southampton   \n",
       "\n",
       "                         home.dest room      ticket   boat     sex  Gender  \\\n",
       "0                     St Louis, MO  B-5  24160 L221      2  female       0   \n",
       "1  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female       0   \n",
       "2  Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male       1   \n",
       "3  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female       0   \n",
       "4  Montreal, PQ / Chesterville, ON  C22         NaN     11    male       1   \n",
       "\n",
       "   PClass  AgeFill  \n",
       "0       1  29.0000  \n",
       "1       1   2.0000  \n",
       "2       1  30.0000  \n",
       "3       1  25.0000  \n",
       "4       1   0.9167  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could fill in the missing ages directly into the age column. But to be extra cautious and not lose the state of \n",
    "# the original data, a more formal way would be to create a new column, AgeFill, and even record which ones were \n",
    "# originally null (and thus artificially guessed).\n",
    "\n",
    "# Make a copy of age:\n",
    "df_titanic['AgeFill'] = df_titanic['age']\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>PClass</th>\n",
       "      <th>age</th>\n",
       "      <th>AgeFill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender  PClass  age  AgeFill\n",
       "12       0       1  NaN      NaN\n",
       "13       1       1  NaN      NaN\n",
       "14       1       1  NaN      NaN\n",
       "29       1       1  NaN      NaN\n",
       "32       1       1  NaN      NaN\n",
       "35       1       1  NaN      NaN\n",
       "40       1       1  NaN      NaN\n",
       "45       1       1  NaN      NaN\n",
       "46       1       1  NaN      NaN\n",
       "52       0       1  NaN      NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at just the rows with missing values, and limit it to the columns important to us right now:\n",
    "df_titanic[ df_titanic['age'].isnull() ][['Gender','PClass','age','AgeFill']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill AgeFill based on our median_ages table. \n",
    "# Here we happen to use the alternate syntax for referring to an existing column, like df.age rather than df['age']. There's a \n",
    "# where clause on df and referencing its column AgeFill, then assigning it an appropriate value out of median_ages.\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        df_titanic.loc[ (df_titanic.age.isnull()) & (df_titanic.Gender == i) & (df_titanic.PClass == j+1), \\\n",
    "                       'AgeFill'] = median_ages[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>PClass</th>\n",
       "      <th>age</th>\n",
       "      <th>AgeFill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender  PClass  age  AgeFill\n",
       "12       0       1  NaN       38\n",
       "13       1       1  NaN       42\n",
       "14       1       1  NaN       42\n",
       "29       1       1  NaN       42\n",
       "32       1       1  NaN       42\n",
       "35       1       1  NaN       42\n",
       "40       1       1  NaN       42\n",
       "45       1       1  NaN       42\n",
       "46       1       1  NaN       42\n",
       "52       0       1  NaN       38"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the exact same 10 rows we just looked at:\n",
    "df_titanic[ df_titanic['age'].isnull() ][['Gender','PClass','age','AgeFill']].head(10)\n",
    "\n",
    "# Note: This confirms we accomplished exactly what we wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a categorical attribute: pclass. We already converted its three classes into 0, 1, and 2. This transformation \n",
    "implicitly introduces an ordering. \n",
    "\n",
    "As a final step, we will try a more general approach that does not assume an ordering. This is widely used to convert categorical classes into real-valued attributes. We will introduce an additional encoder and convert the class attributes into three new binary features, each of them indicating if the instance belongs to a feature value (1) or (0). This is called one hot encoding, and it is a very common way of managing categorical attributes for real-based methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PClass</th>\n",
       "      <th>AgeFill</th>\n",
       "      <th>FirstClass</th>\n",
       "      <th>SecondClass</th>\n",
       "      <th>ThirdClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names pclass  survived  \\\n",
       "0          1    1st         1   \n",
       "1          2    1st         0   \n",
       "2          3    1st         0   \n",
       "3          4    1st         0   \n",
       "4          5    1st         1   \n",
       "\n",
       "                                              name      age     embarked  \\\n",
       "0                     Allen, Miss Elisabeth Walton  29.0000  Southampton   \n",
       "1                      Allison, Miss Helen Loraine   2.0000  Southampton   \n",
       "2              Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   \n",
       "3  Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   \n",
       "4                    Allison, Master Hudson Trevor   0.9167  Southampton   \n",
       "\n",
       "                         home.dest room      ticket   boat     sex  Gender  \\\n",
       "0                     St Louis, MO  B-5  24160 L221      2  female       0   \n",
       "1  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female       0   \n",
       "2  Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male       1   \n",
       "3  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female       0   \n",
       "4  Montreal, PQ / Chesterville, ON  C22         NaN     11    male       1   \n",
       "\n",
       "   PClass  AgeFill  FirstClass  SecondClass  ThirdClass  \n",
       "0       1  29.0000           1            0           0  \n",
       "1       1   2.0000           1            0           0  \n",
       "2       1  30.0000           1            0           0  \n",
       "3       1  25.0000           1            0           0  \n",
       "4       1   0.9167           1            0           0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic['FirstClass'] = df_titanic['pclass'].map( {'1st': 1, '2nd': 0, '3rd': 0} ).astype(int)\n",
    "df_titanic['SecondClass'] = df_titanic['pclass'].map( {'1st': 0, '2nd': 1, '3rd': 0} ).astype(int)\n",
    "df_titanic['ThirdClass'] = df_titanic['pclass'].map( {'1st': 0, '2nd': 0, '3rd': 1} ).astype(int)\n",
    "\n",
    "df_titanic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finalize Dataset for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finalize pre-processing by turning this into a numerical feature set (dataframe titanic_X) and a numerical target column \n",
    "# (dataframe titanic_y)\n",
    "titanic_X = df_titanic[['AgeFill','Gender','FirstClass','SecondClass','ThirdClass']]\n",
    "titanic_y = df_titanic['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeFill</th>\n",
       "      <th>Gender</th>\n",
       "      <th>FirstClass</th>\n",
       "      <th>SecondClass</th>\n",
       "      <th>ThirdClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AgeFill  Gender  FirstClass  SecondClass  ThirdClass\n",
       "0  29.0000       0           1            0           0\n",
       "1   2.0000       0           1            0           0\n",
       "2  30.0000       1           1            0           0\n",
       "3  25.0000       0           1            0           0\n",
       "4   0.9167       1           1            0           0\n",
       "5  47.0000       1           1            0           0\n",
       "6  63.0000       0           1            0           0\n",
       "7  39.0000       1           1            0           0\n",
       "8  58.0000       0           1            0           0\n",
       "9  71.0000       1           1            0           0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    0\n",
       "8    1\n",
       "9    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready for the implementation of decision trees in scikit-learn, as this algo expects as input a list of \n",
    "real-valued features, and the decision rules of the model would be of the form: Feature < value. \n",
    "For example, AgeFill < 20.0.\n",
    "\n",
    "Standardization (normalization) is not an issue for decision trees because the relative magnitude of features does not \n",
    "affect the classifier performance; so scaling is not needed.\n",
    "\n",
    "The preprocessing step is usually under-estimated in machine learning methods, but as we can see even in this very simple \n",
    "example, it can take some time to make data look as our methods expect. It is also very important in the overall machine\n",
    "learning process; if we fail in this step (for example, incorrectly encoding attributes, or selecting the wrong features), \n",
    "the following steps will fail, no matter how good the method we use for learning!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Training a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((984, 5), (984,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to the interesting part; let's build a decision tree from our training data. As usual, we will first separate \n",
    "# training and testing data.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic_X, titanic_y, test_size=0.25, random_state=33)\n",
    "\n",
    "# Show the 'array' size of the numerical data\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, we can create a new DecisionTreeClassifier and use the fit method of the classifier to do the learning job.\n",
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 3, min_samples_leaf = 5)\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Evaluation Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.787 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First define a helper function to measure the performance of a classifier:\n",
    "from sklearn import metrics\n",
    "\n",
    "def measure_performance(X, y, clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred = clf.predict(X)\n",
    "    if show_accuracy:\n",
    "        print(\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\")\n",
    "\n",
    "    if show_classification_report:\n",
    "        print(\"Classification report\")\n",
    "        print(metrics.classification_report(y,y_pred),\"\\n\")\n",
    "\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion matrix\")\n",
    "        print(metrics.confusion_matrix(y,y_pred),\"\\n\")\n",
    "        \n",
    "# And call this method for the training data (display only accuracy)\n",
    "measure_performance(X_test, y_test, clf, show_classification_report=False, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Introducing Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common criticism to decision trees is that once the training set is divided after\n",
    "answering a question, it is not possible to *reconsider this decision*. For example, if\n",
    "we divide men and women, every subsequent question would be only about men or\n",
    "women, and the method could not consider another type of question (say, age less\n",
    "than a year, irrespective of the gender). Random Forests try to introduce some level\n",
    "of randomization in each step, proposing alternative trees and combining them to\n",
    "get the final prediction. These types of algorithms that consider several classifiers\n",
    "answering the same question are called **ensemble methods**. In the Titanic task, it is\n",
    "probably hard to see this problem because we have very few features, but usually\n",
    "a case has in the order of thousand(s) features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests propose to build several decision trees, each one based on a subset of the training\n",
    "instances (selected randomly), and using a small random number of features. \n",
    "This produces multiple classifiers (multiple decision trees). \n",
    "At prediction time, each grown tree, given an instance, predicts its target class exactly as decision trees do. \n",
    "The class that most of the trees vote (that is the class most predicted by the trees) is the one suggested by the ensemble classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Assignment Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a Random Forest classifier. Can you improve to above accuracy? Look at the sklearn documentation. Play with the parameters of the ``RandomForestClassifier``. Especially the parameter ``n_estimators`` (the number of trees in the forest) is of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To do: Implement Random Forest ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
